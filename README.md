# SDD311-BYOL
## Bootstrap Your Own Latent (BYOL)
**Self-Supervised Representation Learning without Negative Pairs**

---

## üìå Description

Ce d√©p√¥t contient un **notebook p√©dagogique et exp√©rimental** consacr√© √† la m√©thode **BYOL (Bootstrap Your Own Latent)**, introduite par Grill et al. (NeurIPS 2020).

Le notebook accompagne une pr√©sentation orale r√©alis√©e dans le cadre du cours **Deep Learning Demo ‚Äì √âvaluation 2025‚Äì2026**.  
Il a pour objectif de **rendre observables les m√©canismes th√©oriques d√©crits dans l‚Äôarticle**, √† travers des exp√©riences simples et reproductibles.

L‚Äôaccent est mis sur :
- l‚Äôapprentissage de repr√©sentations auto-supervis√©es
- le r√¥le des *negative pairs* en contrastive learning
- le ph√©nom√®ne de *representation collapse*
- la mani√®re dont BYOL √©vite ce collapse sans paires n√©gatives

---

## üìö R√©f√©rence

> J.-B. Grill, F. Strub, F. Altch√©, et al.  
> **Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning**  
> NeurIPS 2020

---

## üß† Contenu du notebook

Le notebook suit la progression conceptuelle suivante :

1. Apprentissage de repr√©sentations et augmentations de donn√©es  
2. Baseline contrastive (InfoNCE)  
3. Collapse sans negative pairs (loss attractive uniquement)  
4. Principe de BYOL  
5. Architecture online / target  
6. Stop-gradient et mise √† jour EMA  
7. Entra√Ænement BYOL  
8. Analyse exp√©rimentale :
   - √©volution des losses
   - variance des repr√©sentations
   - visualisations (PCA)
   - comparaisons entre m√©thodes

Les exp√©riences sont volontairement limit√©es en nombre d‚Äôepochs afin de rester ex√©cutables sur CPU.

---

## ‚öôÔ∏è Environnement et ex√©cution

### Ex√©cution recommand√©e

- **Google Colab (CPU)**  
  Le notebook est con√ßu pour √™tre ex√©cut√© sans GPU.
